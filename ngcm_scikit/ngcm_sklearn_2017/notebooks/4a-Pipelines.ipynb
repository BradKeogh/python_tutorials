{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost every machine learning problem involves several steps before you arrive at a final result. Commonly, you must\n",
    "\n",
    "* load the data\n",
    "* clean the data\n",
    "* extract or engineer features\n",
    "* fit a model\n",
    "* evaluate this model\n",
    "* iterate\n",
    "\n",
    "Scikit-learn is designed from the ground up to make these steps easy for users with minimal boilerplate. Recall that there are three (really, four) main objects and interfaces in scikit-learn\n",
    "\n",
    "* Estimators\n",
    "* Predictors\n",
    "* Transformers\n",
    "\n",
    "The scikit-learn [pipeline](http://scikit-learn.org/stable/modules/pipeline.html) abstraction builds on these interfaces to allow us to build chain of transformers and estimators and use the pipeline, as if it were an estimator itself. \n",
    "\n",
    "We've already seen some steps that are common in a machine learning pipeline. In the coming sections, we're going to dive into some more methods that we may also want to use. First, let's fix ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the transformer interface. A transformer is intended to filter or modify the data in a supervised or unsupervised way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "new_data = obj.transform(data)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interface is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class Transformer:\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\"\"\"\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return X\n",
    "        \n",
    "    def fit_transform(self, X, y=None):\n",
    "        self.fit(X, y)\n",
    "        return self.transform(X, y)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator Interface\n",
    "\n",
    "Recall the estimator interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class Estimator:\n",
    "  \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Fit model to data X (and y)\"\"\"\n",
    "        self.some_attribute = self.some_fitting_method(X, y)\n",
    "        return self\n",
    "            \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"Make prediction based on passed features\"\"\"\n",
    "        pred = self.make_prediction(X_test)\n",
    "        return pred\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "estimator = Pipeline([\n",
    "    ('transformer1', Transformer(*args1)),\n",
    "    ('transformer2', Transformer(*args2)),\n",
    "    ('estimator', Estimator(*args))\n",
    "])\n",
    "\n",
    "estimator.fit(X_train, y_train)\n",
    "\n",
    "y_fitted = estimator.predict(X_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By chaining together transformer estimators, our code is much easier to deal with than it would have been otherwise.\n",
    "\n",
    "Under the hood, this calls `fit` on the first transformer, then `transform` on `X` and passes the transformed `X` to the next stop until the final estimator. The pipeline simply calls `fit` on the transformed `X` and `y`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Chaining PCA and Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we can use PCA for unsupervised dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model, decomposition, datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "logistic = linear_model.LogisticRegression()\n",
    "\n",
    "pca = decomposition.PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator = Pipeline(steps=[\n",
    "    ('pca', pca), \n",
    "    ('logistic', logistic)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "\n",
    "(X_digits, X_digits_test, \n",
    " y_digits, y_digits_test) = train_test_split(digits.data, digits.target, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0.,  11.,  10.,   0.,   0.,   0.,   0.,   0.,   8.,\n",
       "         16.,   5.,   0.,   0.,   0.,   0.,   3.,  16.,  10.,   4.,  11.,\n",
       "          0.,   0.,   0.,  11.,  13.,   0.,   9.,  16.,   0.,   0.,   0.,\n",
       "         12.,  13.,   5.,  14.,  16.,   8.,   0.,   0.,   3.,  12.,  14.,\n",
       "         16.,  11.,   3.,   0.,   0.,   0.,   0.,  10.,  11.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,  11.,   8.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   3.,  14.,  13.,  12.,  14.,   0.,   0.,   0.,  11.,\n",
       "         14.,  12.,  15.,   9.,   0.,   0.,   0.,  16.,   5.,   3.,  16.,\n",
       "          2.,   0.,   0.,   1.,   9.,   1.,  10.,  12.,   0.,   0.,   0.,\n",
       "          0.,   0.,   7.,  16.,  14.,   6.,   0.,   0.,   0.,   4.,  16.,\n",
       "         16.,  11.,   1.,   0.,   0.,   0.,   0.,  15.,   5.,   0.,   0.,\n",
       "          0.,   0.,   0.,   6.,  13.,   0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_digits[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAD8CAYAAAD+D4bnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAkDA/wMRxy2LKtaJzwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2343bba8be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(3, 3)\n",
    "\n",
    "def plot_image(ax, img):\n",
    "    ax.imshow(img.reshape(8, 8), cmap=plt.cm.gray_r)\n",
    "    \n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        plot_image(axes[i, j], X_digits[i * 3 + j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 7, 5, 2, 0, 1, 3, 0, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_digits[:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling fit on the estimator runs the whole pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('logistic', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(X_digits, y_digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each fitted transformer or estimator is available from the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pca', 'logistic'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.named_steps.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did we do across classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96666666666666667"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.score(X_digits_test, y_digits_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[38,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 31,  0,  0,  0,  0,  0,  0,  1,  1],\n",
       "       [ 0,  0, 39,  1,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 35,  0,  0,  0,  1,  2,  0],\n",
       "       [ 0,  0,  0,  0, 38,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 27,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  1, 40,  0,  0,  0],\n",
       "       [ 0,  0,  0,  1,  0,  0,  0, 37,  0,  0],\n",
       "       [ 0,  1,  0,  0,  0,  1,  0,  0, 27,  0],\n",
       "       [ 0,  0,  0,  0,  0,  1,  0,  0,  1, 36]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_digits_test, \n",
    "                 estimator.predict(X_digits_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you find naming the steps a little tedious, there is a convenience function called `make_pipeline` that will use the class names for you, avoiding collisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False),\n",
       " 'pca': PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "   svd_solver='auto', tol=0.0, whiten=False)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe = make_pipeline(pca, logistic)\n",
    "\n",
    "pipe.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False),\n",
       " 'pca-1': PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "   svd_solver='auto', tol=0.0, whiten=False),\n",
       " 'pca-2': PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "   svd_solver='auto', tol=0.0, whiten=False)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = make_pipeline(pca, pca, logistic)\n",
    "\n",
    "pipe.named_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avoid Contamination\n",
    "\n",
    "The following is an example of a common gotcha in statistical learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "newsgroups = fetch_20newsgroups(categories=[\n",
    "    'sci.space', 'alt.atheism', 'comp.graphics'\n",
    "])\n",
    "\n",
    "(X, X_test, \n",
    " y, y_test) = train_test_split(newsgroups.data, newsgroups.target)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_vect = vectorizer.fit_transform(X)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "\n",
    "param_grid = {\n",
    "    'C': np.logspace(-1, 2, num=4)\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(clf, param_grid=param_grid, cv=5)\n",
    "\n",
    "grid.fit(X_vect, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can anyone see what we did wrong here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: \n",
    "\n",
    "Create a pipeline out of a [`StandardScaler`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler) and [`Ridge`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge) regression and apply it to the Boston housing dataset (load the data using `sklearn.datasets.load_boston`). Try adding the [`PolynomialFeatures`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) transformer as a second preprocessing step, and grid-search the degree of the polynomials (try 1, 2 and 3).\n",
    "\n",
    "Hint: See the scikit-learn [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn-pipeline-pipeline) on passing parameters to grid search over to the steps in a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dta = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston House Prices dataset\n",
      "===========================\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive\n",
      "    \n",
      "    :Median Value (attribute 14) is usually the target\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "http://archive.ics.uci.edu/ml/datasets/Housing\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      "**References**\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dta['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dta['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'feature_names', 'DESCR'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dta.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dta['data'],columns=dta['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0\n",
       "ZN         0\n",
       "INDUS      0\n",
       "CHAS       0\n",
       "NOX        0\n",
       "RM         0\n",
       "AGE        0\n",
       "DIS        0\n",
       "RAD        0\n",
       "TAX        0\n",
       "PTRATIO    0\n",
       "B          0\n",
       "LSTAT      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dta['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = dta['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import ridge\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scl = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scl.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tran = scl.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test, = train_test_split(x_tran,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mdl.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.32000000e-03,   1.80000000e+01,   2.31000000e+00, ...,\n",
       "          1.53000000e+01,   3.96900000e+02,   4.98000000e+00],\n",
       "       [  2.73100000e-02,   0.00000000e+00,   7.07000000e+00, ...,\n",
       "          1.78000000e+01,   3.96900000e+02,   9.14000000e+00],\n",
       "       [  2.72900000e-02,   0.00000000e+00,   7.07000000e+00, ...,\n",
       "          1.78000000e+01,   3.92830000e+02,   4.03000000e+00],\n",
       "       ..., \n",
       "       [  6.07600000e-02,   0.00000000e+00,   1.19300000e+01, ...,\n",
       "          2.10000000e+01,   3.96900000e+02,   5.64000000e+00],\n",
       "       [  1.09590000e-01,   0.00000000e+00,   1.19300000e+01, ...,\n",
       "          2.10000000e+01,   3.93450000e+02,   6.48000000e+00],\n",
       "       [  4.74100000e-02,   0.00000000e+00,   1.19300000e+01, ...,\n",
       "          2.10000000e+01,   3.96900000e+02,   7.88000000e+00]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load solutions/4a-ridge-grid.py\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "\n",
    "boston = load_boston()\n",
    "X, y = boston.data, boston.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=.2,\n",
    "                                                    random_state=123)\n",
    "\n",
    "param_grid = {\n",
    "    'ridge__alpha': np.logspace(-1, 3, 5),\n",
    "    'polynomialfeatures__degree': [1, 2, 3]\n",
    "}\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    PolynomialFeatures(),\n",
    "    Ridge()\n",
    ")\n",
    "\n",
    "estimator = GridSearchCV(pipeline, param_grid=param_grid, cv=5)\n",
    "estimator.fit(X_train, y_train)\n",
    "\n",
    "print(estimator.score(X_test, y_test))\n",
    "print(estimator.best_score_)\n",
    "print(estimator.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
