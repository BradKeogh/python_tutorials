{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost every machine learning problem involves several steps before you arrive at a final result. Commonly, you must\n",
    "\n",
    "* load the data\n",
    "* clean the data\n",
    "* extract or engineer features\n",
    "* fit a model\n",
    "* evaluate this model\n",
    "* iterate\n",
    "\n",
    "Scikit-learn is designed from the ground up to make these steps easy for users with minimal boilerplate. Recall that there are three (really, four) main objects and interfaces in scikit-learn\n",
    "\n",
    "* Estimators\n",
    "* Predictors\n",
    "* Transformers\n",
    "\n",
    "The scikit-learn [pipeline](http://scikit-learn.org/stable/modules/pipeline.html) abstraction builds on these interfaces to allow us to build chain of transformers and estimators and use the pipeline, as if it were an estimator itself. \n",
    "\n",
    "We've already seen some steps that are common in a machine learning pipeline. In the coming sections, we're going to dive into some more methods that we may also want to use. First, let's fix ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the transformer interface. A transformer is intended to filter or modify the data in a supervised or unsupervised way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "new_data = obj.transform(data)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interface is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class Transformer:\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\"\"\"\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return X\n",
    "        \n",
    "    def fit_transform(self, X, y=None):\n",
    "        self.fit(X, y)\n",
    "        return self.transform(X, y)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator Interface\n",
    "\n",
    "Recall the estimator interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class Estimator:\n",
    "  \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Fit model to data X (and y)\"\"\"\n",
    "        self.some_attribute = self.some_fitting_method(X, y)\n",
    "        return self\n",
    "            \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"Make prediction based on passed features\"\"\"\n",
    "        pred = self.make_prediction(X_test)\n",
    "        return pred\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "estimator = Pipeline([\n",
    "    ('transformer1', Transformer(*args1)),\n",
    "    ('transformer2', Transformer(*args2)),\n",
    "    ('estimator', Estimator(*args))\n",
    "])\n",
    "\n",
    "estimator.fit(X_train, y_train)\n",
    "\n",
    "y_fitted = estimator.predict(X_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By chaining together transformer estimators, our code is much easier to deal with than it would have been otherwise.\n",
    "\n",
    "Under the hood, this calls `fit` on the first transformer, then `transform` on `X` and passes the transformed `X` to the next stop until the final estimator. The pipeline simply calls `fit` on the transformed `X` and `y`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Chaining PCA and Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we can use PCA for unsupervised dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model, decomposition, datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "logistic = linear_model.LogisticRegression()\n",
    "\n",
    "pca = decomposition.PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator = Pipeline(steps=[\n",
    "    ('pca', pca), \n",
    "    ('logistic', logistic)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "\n",
    "(X_digits, X_digits_test, \n",
    " y_digits, y_digits_test) = train_test_split(digits.data, digits.target, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_digits[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(3, 3)\n",
    "\n",
    "def plot_image(ax, img):\n",
    "    ax.imshow(img.reshape(8, 8), cmap=plt.cm.gray_r)\n",
    "    \n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        plot_image(axes[i, j], X_digits[i * 3 + j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_digits[:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling fit on the estimator runs the whole pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator.fit(X_digits, y_digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each fitted transformer or estimator is available from the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator.named_steps.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did we do across classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator.score(X_digits_test, y_digits_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_digits_test, \n",
    "                 estimator.predict(X_digits_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you find naming the steps a little tedious, there is a convenience function called `make_pipeline` that will use the class names for you, avoiding collisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe = make_pipeline(pca, logistic)\n",
    "\n",
    "pipe.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(pca, pca, logistic)\n",
    "\n",
    "pipe.named_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avoid Contamination\n",
    "\n",
    "The following is an example of a common gotcha in statistical learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "newsgroups = fetch_20newsgroups(categories=[\n",
    "    'sci.space', 'alt.atheism', 'comp.graphics'\n",
    "])\n",
    "\n",
    "(X, X_test, \n",
    " y, y_test) = train_test_split(newsgroups.data, newsgroups.target)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_vect = vectorizer.fit_transform(X)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "\n",
    "param_grid = {\n",
    "    'C': np.logspace(-1, 2, num=4)\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(clf, param_grid=param_grid, cv=5)\n",
    "\n",
    "grid.fit(X_vect, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can anyone see what we did wrong here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: \n",
    "\n",
    "Create a pipeline out of a [`StandardScaler`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler) and [`Ridge`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge) regression and apply it to the Boston housing dataset (load the data using `sklearn.datasets.load_boston`). Try adding the [`PolynomialFeatures`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) transformer as a second preprocessing step, and grid-search the degree of the polynomials (try 1, 2 and 3).\n",
    "\n",
    "Hint: See the scikit-learn [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn-pipeline-pipeline) on passing parameters to grid search over to the steps in a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load solutions/4a-ridge-grid.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
